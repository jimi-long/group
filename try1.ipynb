{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Lambda, Subtract\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.layers import Dot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet50(include_top=False, pooling='avg', weights='imagenet')\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "input_left = Input(shape=(200, 245, 3))\n",
    "input_right = Input(shape=(200, 245, 3))\n",
    "\n",
    "encoded_left = base_model(input_left)\n",
    "encoded_right = base_model(input_right)\n",
    "\n",
    "# Cosine similarity between the two encoded outputs\n",
    "cosine_similarity = Dot(axes=1, normalize=True)([encoded_left, encoded_right])\n",
    "prediction = Dense(1, activation='sigmoid')(cosine_similarity)\n",
    "\n",
    "siamese_net = Model(inputs=[input_left, input_right], outputs=prediction)\n",
    "\n",
    "optimizer = Adam(0.0001)\n",
    "siamese_net.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(200, 245))\n",
    "    img_array = image.img_to_array(img)\n",
    "    return preprocess_input(img_array)\n",
    "\n",
    "train_df = pd.read_csv('train.csv')\n",
    "\n",
    "left_images = [load_image(os.path.join('train/left', fname + '.jpg')) for fname in train_df['left']]\n",
    "right_images = [load_image(os.path.join('train/right', fname + '.jpg')) for fname in train_df['right']]\n",
    "labels = np.ones(len(left_images))\n",
    "\n",
    "left_images = np.array(left_images)\n",
    "right_images = np.array(right_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "125/125 [==============================] - 779s 6s/step - loss: 0.6385 - accuracy: 1.0000\n",
      "Epoch 2/2\n",
      "125/125 [==============================] - 717s 6s/step - loss: 0.6208 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d17aa315e0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "siamese_net.fit([left_images, right_images], labels, batch_size=16, epochs=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 9s 2s/step\n"
     ]
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=1, keepdims=True)\n",
    "\n",
    "test_df = pd.read_csv('test_candidates.csv')\n",
    "test_df = test_df.head(5)\n",
    "predictions = []\n",
    "\n",
    "BATCH_SIZE = 5\n",
    "NUM_BATCHES = 1  # 2000 left images divided by 100\n",
    "\n",
    "for batch_idx in range(NUM_BATCHES):\n",
    "    start_idx = batch_idx * BATCH_SIZE\n",
    "    end_idx = start_idx + BATCH_SIZE\n",
    "    \n",
    "    left_img_batch = np.array([load_image(os.path.join('test/left', fname + '.jpg')) for fname in test_df['left'][start_idx:end_idx]])\n",
    "    left_img_batch = np.tile(left_img_batch, (20, 1, 1, 1, 1)).reshape(-1, 200, 245, 3)\n",
    "    \n",
    "    right_imgs = []\n",
    "    for _, row in test_df[start_idx:end_idx].iterrows():\n",
    "        right_imgs.extend([load_image(os.path.join('test/right', row[f'c{i}'] + '.jpg')) for i in range(20)])\n",
    "    right_img_batch = np.array(right_imgs)\n",
    "    \n",
    "    batch_confidences = siamese_net.predict([left_img_batch, right_img_batch])\n",
    "    batch_confidences = batch_confidences.reshape(BATCH_SIZE, 20)\n",
    "    \n",
    "    # Apply softmax\n",
    "    batch_confidences = softmax(batch_confidences)\n",
    "    \n",
    "    for conf in batch_confidences:\n",
    "        predictions.append(conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame(predictions, columns=[f'c{i}' for i in range(20)])\n",
    "submission_df.insert(0, 'left', test_df['left'])\n",
    "submission_df.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
